在传统模式下，处理多个客户端连接有两种基本方法：

- ​**​阻塞 I/O + 多进程/多线程​**​：为每个连接创建一个新的进程或线程。上下文切换开销巨大，且能创建的连接数受限于进程/线程数。
- ​**​非阻塞 I/O + 忙轮询​**​：用一个循环不断遍历所有连接，检查是否有数据可读。CPU 占用率 100%，大部分检查都是无效的，浪费计算资源。

I/O 多路复用完美地解决了上述两种方式的缺陷，它使得​**​单线程​**​可以处理​**​成千上万的网络连接​**​，成为了构建像 Nginx、Redis 这类高性能服务器的基础。

> 什么是IO多路复用

- ​**​阻塞 I/O​**​：你开车去快递站，排队等你的​**​特定一个​**​包裹。如果没到，你就一直在那里等，车占着车道，你也不能干别的。
- ​**​非阻塞轮询​**​：你不停地开车往返于家和快递站，每次都问：“我的包裹到了吗？”，大部分时间都白跑。
- ​**​I/O 多路复用 (`epoll`)​**​：你​**​把手机号留给快递站（注册到内核）​**​。所有包裹到了都先放在货架上。快递站有个智能系统（内核），​**​一旦有你的任何一个包裹到达，就主动发短信通知你（事件就绪）​**​。你只需要在收到短信后，去一趟快递站，就能取到​**​所有已到达的包裹（批量处理）​**​。

# 经典机制

|特性|​**​select​**​|​**​poll​**​|​**​epoll​**​|
|---|---|---|---|
|​**​基本机制​**​|轮询所有fd|轮询所有fd|回调/事件通知|
|​**​数据结构​**​|位图 (fd_set)|链表 (pollfd结构体)|红黑树+就绪链表|
|​**​最大连接数​**​|有限制 (FD_SETSIZE, 通常1024)|无硬性限制 (系统资源决定)|无硬性限制 (系统资源决定)|
|​**​性能与时间复杂度​**​|O(n)，每次调用线性扫描所有fd|O(n)，每次调用线性扫描所有fd|O(1)，仅通知就绪的fd|
|​**​内存拷贝开销​**​|每次调用需在用户态和内核态间复制整个fd_set|每次调用需复制整个pollfd数组|​**​仅首次注册时拷贝​**​，之后无额外拷贝|
|​**​触发模式​**​|仅支持水平触发(LT)|仅支持水平触发(LT)|​**​支持水平触发(LT)和边缘触发(ET)​**​|
|​**​内核实现​**​|简单轮询|简单轮询|​**​基于回调的事件驱动​**​|
|​**​编程复杂度​**​|低|低|中/高 (需理解ET/LT模式)|
|​**​跨平台支持​**​|几乎所有平台|多数Unix系统|​**​主要限于Linux​**​|
### 1. select

​**​改进点 (相对于最原始的多进程模型)：​**​

- ​**​突破性概念​**​：首次实现了​**​单线程监控多路I/O​**​，避免了多进程/多线程的创建和上下文切换开销。
- ​**​通用性强​**​：几乎在所有平台上都可用，移植性好。

​**​缺点与局限性：​**​

- ​**​连接数限制​**​：`FD_SETSIZE`（通常为1024）限制了可监控的fd数量，不适合现代高并发场景。
- ​**​线性扫描性能瓶颈​**​：每次调用都需要遍历所有fd，无论是否就绪，​**​时间复杂度为O(n)​**​。
- ​**​重复初始化​**​：每次调用前都需要重新设置`fd_set`，并在返回后重新遍历所有fd来检查状态。
- ​**​内存拷贝​**​：每次调用都需要将整个fd_set从用户空间复制到内核空间，返回时再复制回来，开销大。

### 2. poll

​**​改进点 (相对于select)：​**​

- ​**​突破连接数限制​**​：使用链表而非固定大小的位图，​**​解除了最大连接数的限制​**​，能管理的fd数量仅受系统资源限制。
- ​**​更细粒度的事件指定​**​：使用`pollfd`结构体，可以为每个fd单独设置关注的事件类型（`events`），并获取更详细的事件结果（`revents`）。

​**​缺点与局限性 (仍未解决的问题)：​**​

- ​**​性能未根本改善​**​：​**​仍然需要线性扫描所有fd​**​（O(n)复杂度）。当连接数很大但活跃连接很少时，大部分扫描都是无效的，效率低下。
- ​**​内存拷贝依然存在​**​：每次调用仍需将整个`pollfd`数组从用户空间复制到内核空间。
- ​**​水平触发​**​：和select一样，只支持水平触发模式，可能导致效率问题（例如，数据未读完会频繁通知）。

### 3. epoll

​**​改进点 (革命性提升，解决了select/poll的所有核心问题)：​**​

- ​**​事件驱动，无需扫描​**​：​**​内核通过回调机制直接管理就绪队列​**​。`epoll_wait`调用时，只需从内核的就绪链表中取事件即可，​**​时间复杂度为O(1)​**​，性能与连接数无关，只与活跃连接数相关。
- ​**​无内存拷贝​**​：使用`epoll_ctl`​**​预先注册fd​**​到内核的红黑树中，此后调用`epoll_wait`时​**​无需重复拷贝fd集合​**​，极大减少了开销。
- ​**​支持边缘触发(ET)​**​：提供了高效的ET模式，​**​一个事件只会被通知一次​**​，除非有新的数据到达，迫使应用程序一次性处理所有数据，减少了系统调用次数，进一步提升了性能。
- ​**​无连接数限制​**​：同样仅受系统资源限制。

​**​缺点与局限性：​**​

- ​**​平台依赖性​**​：​**​基本是Linux特有的API​**​，严重影响了程序的跨平台可移植性。
- ​**​编程复杂度​**​：尤其是​**​边缘触发(ET)模式​**​，需要非常小心地处理。必须循环读取/写入直到返回`EAGAIN`或`EWOULDBLOCK`错误，否则会丢失事件，对开发者要求较高。
# 总结

| 特性              | 阻塞 I/O      | 非阻塞轮询     | I/O 多路复用                       |
| --------------- | ----------- | --------- | ------------------------------ |
| ​**​核心思想​**​    | 一次等一个       | 不停问所有     | 等通知，只处理就绪的                     |
| ​**​线程数​**​     | 多线程（一线程一连接） | 单线程       | ​**​单线程​**​或少量线程               |
| ​**​CPU 利用率​**​ | 低（大量阻塞）     | 100%（忙等待） | ​**​高​**​（等待时无消耗）              |
| ​**​可扩展性​**​    | 差（线程资源有限）   | 差（CPU 耗尽） | ​**​极好​**​（可处理万级连接）            |
| ​**​编程复杂度​**​   | 低           | 中         | 中到高（取决于使用 `select` 还是 `epoll`) |
因此，I/O 多路复用（尤其是 `epoll`）是现代高性能网络编程的基石技术，它使得用少量资源服务海量客户端连接成为可能。​**​ 
